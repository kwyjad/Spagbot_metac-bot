# What will be the best score by an AI on the full Humanity's Last Exam (HLE) before 2026? (QID: 38767)

- Type: numeric

- URL: https://www.metaculus.com/questions/38767/

- Classifier: technology | strategic=False (score=0.00)

### SeenGuard

- enabled=True | lock_status=acquired

- run_filter: before=2 | skipped=0 | after=2

- debug_note=lock acquired

## Research (summary)

CALIBRATION GUIDANCE (auto-generated weekly):
BINARY CALIBRATION
- No resolved binary questions (with pre-resolution forecasts) yet.
- Advice: keep using base rates + small evidence-weighted updates; avoid big swings.

MULTIPLE-CHOICE CALIBRATION (Top-1)
- No resolved MCQ questions (with pre-resolution forecasts) yet.

NUMERIC CALIBRATION (PIT-lite + CRPS)
- No resolved numeric questions (with pre-resolution forecasts) yet.
- When numeric results exist, we’ll check p10/p50/p90 coverage and CRPS.

General takeaway: apply **small** nudges only where gaps are consistent with decent sample sizes (≥10).
— end calibration —

### Reference class & base rates
-   **Reference Class 1: Generational Leap on a Difficult Benchmark.** The performance jump between major AI model generations (e.g., GPT-3.5 to GPT-4, PaLM to Gemini) on a challenging benchmark like MMLU or MATH.
    -   *Base Rate:* A new SOTA model typically improves performance by 15-25 percentage points on such benchmarks. For example, GPT-4's MMLU score (~86%) was a ~16 point improvement over GPT-3.5 (~70%). Applying this to the current HLE SOTA of 26.6% suggests a new score in the **41% to 52%** range.
    -   *Reasoning:* This class assumes a next-generation model (e.g., GPT-5, Gemini 2) is released and benchmarked before 2026. The improvement comes from architectural changes, more data/compute, and better alignment.
-   **Reference Class 2: Early-Stage Benchmark Saturation.** The rate of improvement on a new, difficult benchmark in its first 1-2 years. Benchmarks like MMLU saw rapid progress, moving from near-random performance to high scores within 3-4 years.
    -   *Base Rate:* In the first year after a benchmark's introduction and initial SOTA, it's common to see a significant jump of 20-40 percentage points as the research community focuses on it. This would place the expected score in the **46% to 66%** range.
    -   *Reasoning:* HLE is a new, high-prestige benchmark. Top labs are incentivized to "solve" it quickly. The initial 26.6% score sets a clear target to beat, likely with methods and models already in development.
-   **Limitations:** Both reference classes assume a major model release occurs within the very short (~2.5 month) forecast horizon. The primary uncertainty is not the *size* of the potential jump, but whether the *event* causing the jump happens in time.

### Recent developments (timeline bullets)
-   [2025-10-08] Forbes article highlights AI agents becoming mainstream in 2026, indicating a step-change in capabilities beyond current generative AI is expected soon. (↑) — Suggests underlying models powerful enough for a benchmark leap are anticipated on this timeline.
-   [2025-10-03] Shopify research notes the potential exhaustion of public training data by 2026, a potential long-term headwind for AI progress. (↓) — While a longer-term issue, it could temper the scale of improvement in models currently being trained.
-   [2025-09-16] Medium article cites Anthropic's CEO Dario Amodei believing powerful general AI is possible as early as 2026. (↑) — Reinforces the view from top lab leadership that a major capability leap is imminent.
-   [2025-08-05] Analysis of expert surveys suggests an AGI arrival window between 2026 and 2060, with some industry leaders like Sam Altman targeting the earlier end. (↑) — High-level sentiment from key decision-makers points to a major release being a strategic goal for the end of 2025 or early 2026.
-   [2025-03-18] HLE benchmark is introduced with an initial SOTA of 26.6% from OpenAI. (Neutral) — This sets the baseline. The score is low enough that substantial improvement is possible.

### Mechanisms & drivers (causal levers)
-   **Next-Generation Model Release (Large ↑):** The primary driver. The release and benchmarking of a successor to GPT-4, Gemini 1.5, or Claude 3 would almost certainly cause a large, discontinuous jump in the SOTA score. The forecast is highly sensitive to this binary event.
-   **Advanced Post-Training Enhancements (Moderate ↑):** The current 26.6% score is from "OpenAI's Deep Research," implying it's not just a base model but one augmented with techniques like search, tool-use, or complex chain-of-thought/self-critique. Applying more advanced versions of these methods to a new, more capable base model could amplify gains significantly.
-   **Algorithmic/Architectural Breakthroughs (Moderate ↑):** Novel architectures (e.g., beyond the standard Transformer) or training methods (e.g., process supervision) could unlock capabilities on problems requiring deep reasoning, which HLE is designed to test.
-   **Strategic Delays (Large ↓):** A top lab (e.g., OpenAI) might develop a model capable of a high score but delay its release or the publication of its benchmarks past the Jan 1, 2026 deadline for safety, competitive, or product-related reasons.
-   **Benchmark Difficulty Wall (Moderate ↓):** HLE is designed to test the frontiers of knowledge. It's possible that performance gains are not linear with scaling and that current architectural approaches hit a "wall" on these problems, yielding diminishing returns and a smaller-than-expected jump.

### Differences vs. the base rate (what’s unusual now)
-   **Extremely Short Horizon:** The forecast window is ~2.5 months. Unlike typical 1-2 year forecasts on AI progress, this question is almost entirely a bet on the precise timing of a Q4 2025 / pre-New Year model release from a major lab.
-   **Benchmark Design:** HLE is explicitly designed to be resistant to "tricks" that saturated previous benchmarks. It focuses on frontier scientific knowledge and multimodality, potentially making it harder to improve on via simple scaling compared to text-only, established-knowledge benchmarks like MMLU.
-   **Intense, Concentrated Competition:** The ability to produce a SOTA model on HLE is limited to a very small number of actors (OpenAI, Google DeepMind, Anthropic). The outcome is therefore dependent on the specific corporate strategy and release cadence of just 2-3 companies.
-   **High Anticipation:** There is widespread public and industry expectation for a next-generation model (often dubbed "GPT-5") to be released in late 2025 or early 2026. This forecast is happening at the peak of this anticipation cycle.

### Bayesian update sketch (for the statistician)
-   **Prior:** Based on the reference classes, a reasonable prior would be a bimodal distribution: a high probability mass at the current SOTA (26.6%, representing no new model release) and another distribution centered around **45-55%** (representing a generational leap). For a unimodal approximation, start with a prior centered at **~48%** with a low equivalent n (e.g., n=5) to reflect high uncertainty.
-   **Evidence mapping:**
    -   (↑ Large) Overwhelming consensus from AI leaders and analysts points to a major model release being imminent (late 2025/early 2026).
    -   (↓ Large) The resolution deadline of Jan 1, 2026, is extremely tight. Corporate release schedules can easily slip by a few weeks, which would push a release into 2026 and cause the question to resolve to the current SOTA.
    -   (↑ Moderate) The benchmark is new and prestigious, creating a strong incentive for labs to publish a high score as a show of technical dominance before year-end.
    -   (↓ Moderate) The benchmark's design to test "frontier knowledge" may make it more robust against standard scaling, potentially dampening the size of the jump even if a new model is released.
-   **Net effect:** The evidence reinforces the bimodality. The high likelihood of a new model is countered by the extreme fragility of the timeline. The posterior should have a very wide variance. The median should be pulled down slightly from the reference class prior to account for the significant probability of a release delay, perhaps to the **38-45%** range, but with a fat tail upwards.

### Indicators to watch (leading signals; next weeks/months)
-   **UP indicators:**
    -   Announcements from OpenAI, Google DeepMind, or Anthropic of a new model, even without benchmarks.
    -   Leaked information or credible rumors about an imminent model release or internal HLE scores.
    -   Major AI researchers publishing papers on new architectures or scaling laws that show SOTA performance.
    -   Pre-registration for an API of a new, more powerful model.
-   **DOWN indicators:**
    -   Official statements from top labs pushing back release timelines to "early 2026."
    -   Key AI leaders (e.g., Altman, Hassabis) emphasizing safety, ethics, and deployment of existing models over new capability releases in public talks.
    -   Lack of any significant announcements or leaks by mid-December 2025.
    -   Reports of unexpected difficulty in training next-generation models.

### Caveats & pitfalls
-   **Bimodality Risk:** The forecast distribution is not normal. It is likely a mixture of a spike at 26.6% (no release) and a wider distribution in the 40-70% range (release occurs). The mean/median can be misleading.
-   **Corporate Secrecy:** The key driver (a model release) is a private corporate decision. It may be made and executed with little to no public warning, making leading indicators unreliable. A lab could also achieve a high score and not release it.
-   **Benchmark Integrity:** While unlikely, any leak of the HLE test set to a model's training data would invalidate results and complicate resolution.
-   **Definition of "AI System":** The criteria allow "post-training enhancements." A very complex system of multiple models, search engines, and code interpreters could be used. The line between this and "human assistance" could become blurry, though the criteria seem clear for now.
-   **"Hollywood" Release:** A company could announce a model and its score in late December but not make the model widely available until 2026. This would still count for resolution as long as the result is credibly published.

**Final Research Summary:** The forecast hinges almost entirely on whether a next-generation AI model is released and benchmarked by a top lab before January 1, 20

Market snapshot debug:
- Metaculus: no open binary results in response
- Manifold: no open binary results in response

### Sources
- Why Breaking Down the Latest AGI Timelines and Breakthroughs from 2022 to 2025 Reveals a Game-Changing Arrival Window for Super AI (medium.com) — https://medium.com/@shailendrakumar_6211/why-breaking-down-the-latest-agi-timelines-and-breakthroughs-from-2022-to-2025-reveals-a-game-changing-b2c28d43389a
- Entering The Artificial General Intelligence Spectrum In 2025 (www.forbes.com) — https://www.forbes.com/sites/forbestechcouncil/2025/01/07/entering-the-artificial-general-intelligence-spectrum-in-2025/
- The Future of Artificial Intelligence: Impacts and Risks (2025) (www.shopify.com) — https://www.shopify.com/research/future-of-ai
- The AGI Revolution: Why 2025 Could Be The Year Everything Changes (medium.com) — https://medium.com/@micheallanham/the-agi-revolution-why-2025-could-be-the-year-everything-changes-a5d3512b353d
- Artificial General Intelligence: Is AGI Really Coming by 2025? (hyperight.com) — https://hyperight.com/artificial-general-intelligence-is-agi-really-coming-by-2025/
- AGI could now arrive as early as 2026 — but not all scientists agree (www.livescience.com) — https://www.livescience.com/technology/artificial-intelligence/agi-could-now-arrive-as-early-as-2026-but-not-all-scientists-agree
- AI revolution or hype? Experts split on future of artificial general intelligence (www.turkiyetoday.com) — https://www.turkiyetoday.com/world/ai-revolution-or-hype-experts-split-on-future-of-artificial-general-intelligence-43639/
- The 8 AI Agent Trends For 2026 Everyone Must Be Ready For Now (www.forbes.com) — https://www.forbes.com/sites/bernardmarr/2025/10/08/the-8-ai-agent-trends-for-2026-everyone-must-be-ready-for-now/

### Research (debug)

- source=GoogleGrounding | llm=google/gemini-2.5-pro | cached=0 | n_raw=10 | n_kept=8 | cost=$0.027253

- query: artificial general intelligence.; format; metac_closes_in_period; info; post_id; question_id; Last Exam; Deep Research; 2025; 2026

### GTMC1 (debug)

- strategic_class=False | strategic_score=0.00 | source=llm

- gtmc1_active=False | qtype=numeric | t_ms=0

- actors_parsed=0

- exceedance_ge_50=None | coalition_rate=None | median=None | dispersion=None

### Ensemble (model outputs)

- OpenRouter-Default: ok=True t_ms=13873 P10=2026.000, P50=1.000, P90=1.000

- Claude-3.7-Sonnet (OR): ok=True t_ms=21443 P10=2026.000, P50=1.000, P90=1.000

- Gemini: ok=True t_ms=68618 P10=1.000, P50=5.000, P90=1.000

- Grok: ok=False t_ms=74



### Per-model (raw + usage/cost)

#### OpenRouter-Default

- ok=True | t_ms=13873 | tokens: prompt=3983, completion=549, total=4532 | cost=$0.015448

```md

To forecast the best score by an AI on Humanity's Last Exam (HLE) before 2026, let's follow the structured approach:

1. **Base Rate (Prior) Selection**
   - **Reference Class 1: Generational Leap on a Difficult Benchmark.** Historical improvements on benchmarks like MMLU suggest a 15-25 percentage point increase with new model generations. This places the expected score in the 41% to 52% range.
   - **Reference Class 2: Early-Stage Benchmark Saturation.** Initial rapid progress on new benchmarks suggests a 20-40 percentage point increase, placing the expected score in the 46% to 66% range.
   - **Chosen Base Rate:** A weighted average of these classes suggests a prior centered around 48% with a wide variance due to the uncertainty of a new model release.

2. **Comparison to Base Case**
   - **Similarities:** The rapid pace of AI development and historical trends of quick benchmark saturation.
   - **Differences:** The extremely short forecast horizon and the benchmark's design to resist simple scaling improvements.

3. **Evidence Evaluation (Likelihoods)**
   - **Positive Evidence:** Anticipation of a major model release by late 2025, strong incentives for labs to achieve high scores, and expert predictions of imminent AI advancements.
   - **Negative Evidence:** The tight timeline for a release, potential strategic delays by labs, and the benchmark's difficulty.
   - **Net Effect:** The likelihood of a new model release is high, but the timeline fragility tempers expectations.

4. **Bayesian Updating (Posterior Distribution)**
   - **Prior:** Centered at 48% with high uncertainty.
   - **Likelihood:** High probability of a new model release, but significant risk of delay.
   - **Posterior:** A bimodal distribution with a spike at 26.6% (no release) and a broader distribution around 45-55% (release occurs).

5. **Red Team Thinking**
   - **Overconfidence Check:** The forecast should account for the possibility of no release, which is significant given the timeline.
   - **Tail Risks:** Consider the chance of a breakthrough or strategic delay.
   - **Alternative Forecast:** A conservative estimate might place more weight on the current SOTA, but the anticipation of a release justifies a higher median.

6. **Final Percentiles**
   - Given the evidence and considerations, the forecast is adjusted to reflect the bimodal nature and timeline risks.

P10: 27  
P20: 30  
P40: 38  
P60: 45  
P80: 55  
P90: 65

```

#### Claude-3.7-Sonnet (OR)

- ok=True | t_ms=21443 | tokens: prompt=4509, completion=1035, total=5544 | cost=$0.029052

```md

# Forecast: Best Score by an AI on Humanity's Last Exam (HLE) Before 2026

## 1. Base Rate (Prior) Selection

I'll use two key reference classes to establish my prior:

1. **Recent AI benchmark progress rates**: The current SOTA on HLE is 26.6% from OpenAI's Deep Research. For similar challenging benchmarks (like MMLU, MATH), we typically see improvements of 15-25 percentage points between major model generations.

2. **Early-stage benchmark saturation**: New prestigious benchmarks often see rapid initial progress as labs focus resources on them. In the first 1-2 years, improvements of 20-40 percentage points are common.

Combining these reference classes, my prior distribution has a median around 45-50%, with substantial uncertainty given the short timeframe (less than 3 months until resolution).

## 2. Comparison to Base Case

**Similarities to base rate:**
- HLE is a prestigious new benchmark that top labs are incentivized to perform well on
- The current score (26.6%) leaves substantial room for improvement
- The pattern of rapid initial progress on new benchmarks is well-established

**Differences from base rate:**
- The extremely short timeframe (~2.5 months) means we're essentially forecasting whether a new major model will be released and benchmarked before Jan 1, 2026
- HLE is explicitly designed to be more challenging than previous benchmarks, testing frontier knowledge and multimodal reasoning
- The question resolves based on a binary event (new model release) with a tight deadline, creating a bimodal distribution

## 3. Evidence Evaluation (Likelihoods)

**Evidence supporting higher scores:**
- Multiple industry leaders (Altman, Amodei) have indicated expectations for powerful new AI by early 2026 (likelihood ratio ~2:1 favoring higher scores)
- The timing aligns with expected release cycles for next-generation models from major labs (likelihood ratio ~1.5:1)
- HLE's prestige creates strong incentives for labs to demonstrate capabilities on it (likelihood ratio ~1.3:1)

**Evidence supporting lower scores:**
- The extremely tight timeline (by Jan 1, 2026) means even minor delays could push a release beyond the resolution date (likelihood ratio ~3:1 favoring lower scores)
- HLE's design to test frontier knowledge may make it more resistant to simple scaling (likelihood ratio ~1.2:1)
- Corporate release schedules frequently slip by weeks or months (likelihood ratio ~2:1)

## 4. Bayesian Updating (Posterior Distribution)

Starting with my prior centered around 45-50%, I need to update based on the key evidence:

The strongest factor is the extremely tight timeline, which significantly increases the probability that no new model will be released and benchmarked before Jan 1, 2026. This creates a bimodal distribution:

- Mode 1: ~26.6% (current SOTA) if no new model is released in time
- Mode 2: ~50-60% if a new model is released and benchmarked

Given the timeline constraints, I assign approximately a 60% probability to Mode 1 and 40% probability to Mode 2. This pulls my median estimate down to around 35-40%.

## 5. Red Team Thinking

**Potential blind spots:**
- I may be underestimating the probability of a surprise announcement from a major lab in December
- I might be overestimating the improvement a new model would bring on this specific benchmark
- The bimodal nature of the distribution makes point estimates misleading

**Alternative scenarios:**
- A lab could release a model in late December with only partial HLE results, complicating resolution
- A specialized model focused specifically on HLE could achieve higher scores than expected
- Multiple labs could release competing models, driving rapid score improvements

I should widen my uncertainty bands to account for these possibilities, particularly on the upside.

## 6. Final Percentiles

After considering all evidence and potential blind spots, I arrive at a distribution that reflects the bimodal nature of this forecast:

P10: 26.6
P20: 26.6
P40: 32.0
P60: 45.0
P80: 58.0
P90: 65.0

## 7. Output Format

P10: 26.6
P20: 26.6
P40: 32.0
P60: 45.0
P80: 58.0
P90: 65.0

```

#### Gemini

- ok=True | t_ms=68618 | tokens: prompt=4374, completion=1421, total=12972 | cost=$0.019678

```md

Here is a full probabilistic forecast following the specified Bayesian reasoning steps.

### 1. Base Rate (Prior) Selection

The primary uncertainty is whether a next-generation AI model (e.g., "GPT-5" class) will be released and benchmarked before January 1, 2026. This creates a bimodal distribution for the potential score. Therefore, the prior is a mixture model based on two scenarios:

*   **Scenario A: No new SOTA-setting model is released in time.** The score remains at or very near the current State-of-the-Art (SOTA) of 26.6%.
*   **Scenario B: A new SOTA-setting model is released.** The score makes a "generational leap."

To establish a base rate for the *size* of this leap (Scenario B), I use the reference class of performance jumps on difficult benchmarks (e.g., MMLU, MATH) between major model versions (like GPT-3.5 to GPT-4). This suggests a typical improvement of **15-25 percentage points**. Applying this to the current 26.6% SOTA yields a distribution for the new score centered around **42% to 52%**.

The most critical part of the prior is the probability assigned to each scenario. Given the very short ~2.5 month timeline, corporate release schedules are fragile and prone to delays. While anticipation for a new model is high, a slip of even a few weeks would push a release into 2026. I therefore set a conservative prior probability of **P(Release in time) = 40%**.

This creates a prior distribution with a 60% probability mass clustered at 26.6% and a 40% probability mass in a distribution centered around ~48%.

### 2. Comparison to Base Case

*   **Similarities:** The competitive environment among top AI labs (OpenAI, Google, Anthropic) is intense, mirroring past periods of rapid benchmark progress. The target, HLE, is a new and prestigious benchmark, creating strong incentives for labs to claim the top spot.
*   **Differences:**
    *   **Extreme Time Constraint:** The ~2.5 month window is the most significant difference from a typical 1-2 year forecast. It elevates the probability of the "no new release" scenario due to potential slippage in timelines.
    *   **Benchmark Difficulty:** HLE is explicitly designed to test frontier scientific knowledge and resist simple saturation through scaling. This suggests the performance jump from a new model might be on the lower end of the historical 15-25 point range, as the problems are fundamentally harder than those on benchmarks like MMLU.

### 3. Evidence Evaluation (Likelihoods)

*   **(↑) Evidence for a Higher Score (Release Occurs):**
    *   **Expert Commentary:** Public statements from leaders like Dario Amodei (Anthropic) and the general sentiment around Sam Altman (OpenAI) point to a major capability leap being imminent (late 2025/early 2026). This is strong evidence that models capable of achieving a high score are in the final stages of development.
    *   **Incentive Structure:** The prestige of HLE creates a powerful incentive for a lab to publish a high score before year-end as a demonstration of technical dominance.

*   **(↓) Evidence for a Lower Score (No Release / Small Jump):**
    *   **Timeline Fragility:** This is the strongest evidence for a low outcome. A 2.5-month window is very tight for a major software/model release, which often faces last-minute delays for safety, performance, or strategic reasons. This strongly supports the 60% mass at the low end of the distribution.
    *   **Benchmark Robustness:** The design of HLE to test "frontier knowledge" might dampen the returns from scaling alone. This suggests that even if a new model is released, the jump might be smaller than historical precedents, slightly lowering the mean of the "leap" distribution.

### 4. Bayesian Updating (Posterior Distribution)

My initial prior was a 60/40 mixture of "no release" vs. "release". The evidence reinforces this structure rather than shifting it dramatically. The strong evidence for imminent models is almost perfectly counteracted by the strong likelihood of a minor schedule slip pushing a release past the deadline.

Therefore, I will maintain the 60/40 probability split. My posterior distribution has two distinct components:

1.  A 60% chance that the score remains very close to the current 26.6%. This will inform the percentiles up to P60.
2.  A 40% chance that the score jumps to a new value from a "leap distribution." This distribution is centered around **48-50%**, reflecting a significant but perhaps slightly tempered generational improvement due to HLE's difficulty. This will inform the percentiles from P60 upwards.

The resulting posterior is strongly bimodal, with a large gap between the 60th percentile and the 80th percentile. The median of the distribution will be low, just above the "no release" cluster of outcomes.

### 5. Red Team Thinking

A key vulnerability in my forecast is the 40% probability of a release. This might be too high. What if the top labs have made a strategic decision to delay releases until mid-2026 to focus on safety or product integration? In that case, the probability of a release is near zero. This would collapse my forecast onto the current 26.6% score.

Conversely, I might be underestimating the size of the potential leap. An architectural breakthrough, not just scaling, could be part of the next model generation, potentially leading to a score of 70% or higher. My P90 at 58% might be too conservative and not account for this upside tail risk.

To account for these possibilities, I will slightly widen my final distribution. I will keep the median low to reflect the high chance of no release, but I will increase the P90 slightly to account for a surprisingly large jump, while ensuring the lower percentiles reflect the high probability of stagnation. The final percentiles reflect a 60% chance of the score remaining below 31% and a 40% chance of a significant jump.

### 6. Final Percentiles

P10: 27
P20: 28
P40: 29
P60: 31
P80: 50
P90: 58

```

#### Grok

- ok=False | t_ms=74 | tokens: prompt=0, completion=0, total=0 | cost=$0.000000

- error=HTTP 429: Your team 0101076a-72f1-4f25-a038-b346d74bbc8d has either used all available credits or reached its monthly spending limit. To continue making API requests, please purchase more credits or raise your spending limit.

### Aggregation (BMC)

- final_quantiles: P10=-830.0551038588475, P50=0.9921106251178078, P90=816.66707343739

- bmc_summary={"mean": -5.87428586498639, "p10": -830.0551038588475, "p50": 0.9921106251178078, "p90": 816.66707343739}