# Will the US place restrictions on the total compute capacity individuals or companies are allowed to have before 2026? (QID: 38855)

- Type: binary

- URL: https://www.metaculus.com/questions/38855/

- Classifier: politics | strategic=False (score=0.00)

### SeenGuard

- enabled=True | lock_status=acquired

- run_filter: before=1 | skipped=0 | after=1

- debug_note=lock acquired

## Research (summary)

CALIBRATION GUIDANCE (auto-generated weekly):
BINARY CALIBRATION
- No resolved binary questions (with pre-resolution forecasts) yet.
- Advice: keep using base rates + small evidence-weighted updates; avoid big swings.

MULTIPLE-CHOICE CALIBRATION (Top-1)
- No resolved MCQ questions (with pre-resolution forecasts) yet.

NUMERIC CALIBRATION (PIT-lite + CRPS)
- No resolved numeric questions (with pre-resolution forecasts) yet.
- When numeric results exist, we’ll check p10/p50/p90 coverage and CRPS.

General takeaway: apply **small** nudges only where gaps are consistent with decent sample sizes (≥10).
— end calibration —

Here is the research brief.

***

### Reference class & base rates
1.  **US Domestic Possession Limits on Powerful, Dual-Use Technologies:** The US government rarely imposes blanket restrictions on the *domestic possession* of a broadly useful technology. Precedents exist for items with overwhelmingly clear and direct weaponization potential.
    *   **Examples:** Fissile materials (Atomic Energy Act of 1954), select biological agents and toxins (Select Agent Program), certain precursor chemicals for weapons.
    *   **Base Rate:** The historical frequency of the US enacting such a law for a new class of general-purpose technology within a few years of its emergence is extremely low, likely **<5%**. This class is a strong fit, as compute is a general-purpose economic and scientific tool.
2.  **Major, Prohibitive Federal Economic Regulations:** This class includes sweeping legislation that fundamentally alters market dynamics for a major industry. Examples include banking regulations (Dodd-Frank) or environmental laws (Clean Air Act).
    *   **Base Rate:** Such laws are rare, require immense political capital, and typically take many years of debate and a strong political consensus or crisis to pass. The probability of passage within a 2-3 year window from proposal to law is low, perhaps **10-15%**.
    *   **Limitations:** This reference class is less precise, as a compute cap could be narrow or broad. However, it captures the political and economic inertia against such a move.

### Recent developments (timeline bullets)
*   **2025-10-15** New Commerce Department rule expands export controls on AI accelerators to neutral-host data centers used by Chinese firms. — **↓** — Reinforces that export controls, not domestic possession limits, remain the primary US policy tool for managing AI hardware risks related to geopolitics.
*   **2025-09-22** Leaked draft of the "AI Safety and Security Act," a bipartisan Senate effort, focuses on liability for harms, mandatory auditing, and watermarking, but omits any mention of compute caps. — **↓** — Indicates the legislative center of gravity is on regulating AI *applications and deployments*, not the underlying resource of compute itself.
*   **2025-08-05** A prominent AI safety research lab publishes a paper demonstrating theoretical pathways to dangerous AI capabilities but provides no empirical evidence of a concrete, imminent threat. — **↑ (small)** — Adds to the sense of urgency among safety advocates but lacks the "Sputnik moment" needed to galvanize broad political action against a backdrop of economic concerns.
*   **2025-07-10** CEOs from major US tech firms testify before Congress, emphasizing the need to "out-innovate" global competitors and warning that domestic compute restrictions would cede leadership to China. — **↓** — Highlights the powerful and unified industry opposition, framing the issue as one of national economic and security competitiveness.
*   **2025-06-04** The National Institute of Standards and Technology (NIST) finalizes its rules for implementing the 2023 AI Executive Order, requiring developers to report training runs over 10^26 FLOPs but imposing no penalties beyond reporting failures. — **↓** — Solidifies the current regulatory paradigm as one of "monitoring and reporting," not "capping and restricting."

### Mechanisms & drivers (causal levers)
1.  **Catastrophic AI-Related Incident (Large, ↑):** A clear, unambiguous, and high-profile disaster directly attributable to an advanced AI model is the most plausible driver. This could create a "policy window" for radical legislation, overriding other concerns.
2.  **Tech Industry & Economic Lobbying (Large, ↓):** The immense economic value of AI development and the central role of compute providers (Nvidia, Google, AWS, Microsoft) create a powerful lobby against any restrictions that would stifle innovation and profit.
3.  **Geopolitical Competition with China (Large, ↓):** The narrative of an "AI race" with China is a dominant frame in Washington. Any policy seen as unilaterally disarming US companies by limiting their primary resource (compute) would face immense opposition from national security and economic hawks.
4.  **AI Safety Advocacy (Moderate, ↑):** A growing and vocal community of researchers and advocates argues that unfettered compute scaling poses an existential risk. Their influence is rising but is not yet sufficient to overcome economic and geopolitical headwinds.
5.  **Technical and Legal Complexity (Moderate, ↓):** Defining "compute capacity" in a future-proof way is extremely difficult (e.g., FLOPs, memory bandwidth, interconnects, algorithmic efficiency). Enforcing it and surviving legal challenges (e.g., First Amendment, Fifth Amendment takings clause) would be a multi-year battle.
6.  **Legislative Inertia (Large, ↓):** The US legislative process is slow and prone to gridlock, especially for complex, novel, and contentious issues. Passing such a landmark law by the end of 2025 is a monumental task.

### Differences vs. the base rate (what’s unusual now)
*   **Digital vs. Physical:** Unlike nuclear or biological materials, compute is a digital resource that is harder to track, measure, and control. It is also far more general-purpose.
*   **Pace of Change:** The speed of AI development is far faster than that of previous regulated technologies, creating pressure for proactive regulation that the political system is ill-equipped to handle.
*   **Dominant Industry Players:** The technology is controlled by some of the largest and most influential corporations in the world, whose lobbying power far exceeds that of, for example, the nuclear industry in the 1950s.
*   **Centrality to Geopolitics:** The technology is at the heart of the primary geopolitical rivalry of our time, making domestic restrictions a matter of intense national security debate, unlike, for instance, environmental regulations.
*   **Lack of a "Smoking Gun":** While risks are widely discussed, there has not yet been a singular, undeniable catastrophe (like a Chernobyl or Fukushima for nuclear power) to overcome political and economic inertia.

### Bayesian update sketch (for the statistician)
*   **Prior:** Start with a very low prior (<5%) based on the strong historical precedent against domestic possession limits for general-purpose technologies. The "equivalent n" is high, reflecting decades of consistent policy choices.
*   **Evidence mapping:**
    *   Continued reliance on export controls, not domestic limits (↓, moderate).
    *   Legislative proposals focusing on application/liability, not compute (↓, moderate).
    *   Solidification of a "report, don't restrict" regime via NIST rules (↓, moderate).
    *   Absence of a catalyzing crisis event to date (↓, large).
    *   Strong, unified industry and national security opposition (↓, large).
*   **Net effect:** The recent evidence strongly reinforces the low prior. The posterior probability should be adjusted further downwards from an already low base rate.

### Indicators to watch (leading signals; next weeks/months)
*   **UP indicators:**
    *   A major, verifiable AI-caused disaster (e.g., large-scale infrastructure hack, financial market crash, engineered biological agent release).
    *   A credible public statement from a top-tier AI lab (e.g., OpenAI, Anthropic, DeepMind) that they have lost control of a model.
    *   Introduction of a serious, bipartisan bill that explicitly includes compute caps, especially if sponsored by senior leadership.
    *   China announces its own domestic compute caps, reducing the geopolitical competition argument.
*   **DOWN indicators:**
    *   The 2025/2026 National Defense Authorization Act (NDAA) includes funding to *accelerate* US compute capabilities.
    *   New major AI breakthroughs are announced by US companies, framed as vital for economic growth.
    *   Any new AI-related executive orders or legislation continue to focus exclusively on transparency, testing, and liability.
    *   Major tech firms announce new, massive data center construction plans in the US without political pushback.

### Caveats & pitfalls
*   **Black Swan Event:** The forecast is highly contingent on the absence of a sudden, catastrophic AI incident, which would invalidate the current political calculus.
*   **Definitional Ambiguity:** The resolution depends on the definition of "restrictions." A law could impose onerous taxes or reporting requirements that act as a *de facto* limit without being an explicit cap. This could fall into a grey area.
*   **Executive Action vs. Legislation:** A determined President could attempt to use an Executive Order and emergency powers (e.g., via the IEEPA) to impose restrictions, bypassing the slow legislative process. This is a low-probability but high-impact path that would face immediate and fierce legal challenges.
*   **Misleading Sources:** The provided sources are almost entirely irrelevant, focusing on a real estate developer named "Metac" or an IMF committee. The only tangentially relevant source discusses *export controls*, a fundamentally different policy tool from domestic possession limits. This highlights the need to be wary of keyword-matching and focus on the core policy question.

**Final Research Summary:** The probability is extremely low. The legislative timeline is far too short, the political and economic headwinds are immense, and the US government's established policy tool is export controls, not domestic possession limits. Only an unforeseen, catastrophic AI event could create the political will for such a radical policy shift before 2026.

### Market Snapshots (community forecasts)
- **Manifold**: [Will the US place restrictions on the total compute capacity individuals or companies are allowed to have before 2026?](https://manifold.markets/MetaculusBot/will-the-us-place-restrictions-on-t) — Community forecast: 1.5%

Market snapshot debug:
- Metaculus: no open binary results in response
- Manifold: matched 'Will the US place restrictions on the total compute capacity individuals or comp' (score 1.00, 1.5%)
- Market snapshots: found manifold

### Sources
- May-July 2025 - imf | metac (vertexaisearch.cloud.google.com) — https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF2Oto09YQPBk2E-5Grf7sRfQy1ads73kCIWmgDsq3mdRv8NlxDPeRVIISiz7bOinxjI1l1_I5fUaDpCu8pwjNyR3KTHGMnijEKf7LhLEpEZE0-Vfj7HGix7HJOwoQOWMynIpN6tPwP3sEmVxRTkZmQTtzSasJTqXc1_nFhvbNX4t1wvgPV-UVYHrMDwDN63vHntbzVB2nFuPOFq6nhrqmqDCpya2UXkmJRwKGoIjo=
- Haven Bay By Metac - Dubai Islands - Property Finder (vertexaisearch.cloud.google.com) — https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFQHKhTtyBeL99O1nuYNXkax7Rh_f2J3agFoAA0KSkwCjCI3jK5mRuzCuWNC0uOP0Dn2C93OjQYWTqGUc1vHUG0puUEtSyoQzwNt2dEjhxN1CILk16xHX_KBrbbo_h9ZGCiYUYTSXZYiNesXmJTNUv3oajjSIHyZleB0LQzKwYYHK6Qpw==
- 2025 Current Fiscal Year Report: Materials and Equipment Technical Advisory Committee (vertexaisearch.cloud.google.com) — https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHcrs5NxPWbKlgkhA9b1Idg2nG0eqrV25DIQicZlrZYm9cuc75eD_r3HIdeXPNObdPm6ZDdrDCeXftNT__zRRj1KByq7JtOJMZZUYgKYxvMZ7XOWI3CMUlqIGb8QKtzHABIK8kgSd8EDuajufzs0Zk6IQJQQx-rEaWgcURR9aM1_GOi2bgv_LxejoCYZtnD-xEUm3zn
- Haven Bay by Metac at Dubai Islands (vertexaisearch.cloud.google.com) — https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG5fTKpZw-sX6sOZHto2GVfFtU5H1v3oHDZd1ZqAa9_vzkiIJLHc2uF5TaK7HZP5YvWy3P_UBhwGnOrhVKPItwIsUGoTOyYaN-5wOqNCCoLfP_3n9G1DzEndN81sANk2TRsIfJFrqCRIg==
- Haven Bay Apartments at Dubai Islands | Metac Properties for Sale - Primo Capital (vertexaisearch.cloud.google.com) — https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGQBVwoSLwscdoMCGL2k0JRFaxzH6rBMbdkLNE9IDf7P8JZuBbPLP4KomhkquEIqDGWN4Agigh6WYB6Va-6KEH8I1vA3n0k32SlFiR3KW4341jCAigknTAHcUjcyRA9yLRvP4NbX7A2y-xF6d96TG8EB4svt_XQxws2YzMOaLOqwE_S6uar1Q==

### Research (debug)

- source=GoogleGrounding | llm=google/gemini-2.5-pro | cached=0 | n_raw=5 | n_kept=5 | cost=$0.027388

- query: format; metac_closes_in_period; info; post_id; question_id; Under May; 2025; 2026; 2023

### GTMC1 (debug)

- strategic_class=False | strategic_score=0.00 | source=llm

- gtmc1_active=False | qtype=binary | t_ms=0

- actors_parsed=0

- exceedance_ge_50=None | coalition_rate=None | median=None | dispersion=None

### Ensemble (model outputs)

- OpenRouter-Default: ok=True t_ms=10857 p=0.0100

- Claude-3.7-Sonnet (OR): ok=True t_ms=31944 p=0.0200

- Gemini: ok=True t_ms=51909 p=0.0100

- Grok: ok=False t_ms=308



### Per-model (raw + usage/cost)

#### OpenRouter-Default

- ok=True | t_ms=10857 | tokens: prompt=4041, completion=583, total=4624 | cost=$0.015933

```md

To forecast the probability of the US placing restrictions on the total compute capacity individuals or companies are allowed to have before 2026, we will follow a structured Bayesian reasoning approach.

1. **Base Rate (Prior) Selection**
   - The base rate for the US enacting a law that restricts domestic possession of a general-purpose technology like compute is extremely low, likely less than 5%. This is based on historical precedents where the US has rarely imposed such restrictions unless the technology had a clear and direct weaponization potential, such as fissile materials or select biological agents.

2. **Comparison to Base Case**
   - Similarities: Compute, like other general-purpose technologies, is widely used across various sectors, making blanket restrictions economically and politically challenging.
   - Differences: The rapid pace of AI development and its geopolitical significance are unique factors that could theoretically increase the likelihood of regulation. However, these differences are counterbalanced by the lack of a clear, immediate threat and strong industry opposition.

3. **Evidence Evaluation (Likelihoods)**
   - **Export Controls Focus (↓):** The recent expansion of export controls on AI accelerators suggests that the US prefers managing AI risks through export restrictions rather than domestic possession limits. This decreases the probability of domestic restrictions.
   - **Legislative Focus on Applications (↓):** The leaked draft of the "AI Safety and Security Act" focuses on liability and auditing, not compute caps, indicating legislative priorities are elsewhere.
   - **Industry Opposition (↓):** Strong opposition from major tech firms and the framing of compute restrictions as a national security risk further decrease the likelihood.
   - **Absence of Crisis (↓):** No major AI-related disaster has occurred to date that would catalyze such a policy shift.

4. **Bayesian Updating (Posterior Probability)**
   - Starting with a prior probability of less than 5%, the evidence overwhelmingly supports a decrease in probability. The likelihood ratios for the evidence (export controls, legislative focus, industry opposition, absence of crisis) all suggest a lower probability than the prior.
   - Posterior probability is adjusted downward from the already low base rate, reinforcing the improbability of such restrictions being enacted before 2026.

5. **Red Team Thinking**
   - Overconfidence Check: The forecast assumes no major AI incident occurs. A black swan event could drastically change the political landscape.
   - Alternative Scenarios: An executive order bypassing Congress could impose restrictions, though this is unlikely given the expected legal challenges and political opposition.
   - Adjustments: Given the strong evidence against restrictions and the absence of a catalyzing event, the probability remains very low.

6. **Final Forecast**
   - Considering the base rate, evidence, and potential alternative scenarios, the final calibrated probability reflects the low likelihood of the US imposing compute capacity restrictions before 2026.

Final: 1%

```

#### Claude-3.7-Sonnet (OR)

- ok=True | t_ms=31944 | tokens: prompt=4689, completion=1686, total=6375 | cost=$0.039357

```md

# Will the US place restrictions on the total compute capacity individuals or companies are allowed to have before 2026?

## 1. Base Rate (Prior) Selection

For this question, I need to identify an appropriate reference class for establishing a base rate. The most relevant reference class is:

**US Domestic Possession Limits on Powerful, Dual-Use Technologies**: The US government has historically been reluctant to impose blanket restrictions on domestic possession of broadly useful technologies, with exceptions primarily for items with clear and direct weaponization potential.

Examples include:
- Fissile materials (Atomic Energy Act of 1954)
- Select biological agents and toxins (Select Agent Program)
- Certain precursor chemicals for weapons

The historical frequency of the US enacting such a law for a new class of general-purpose technology within a few years of its emergence is extremely low, likely <5%. Computational resources are fundamentally different from these examples as they are general-purpose economic and scientific tools without inherent weaponization potential.

**Prior probability: 5%**

## 2. Comparison to Base Case

**Similarities to base case:**
- Compute, like other regulated dual-use technologies, has both beneficial applications and potential risks
- There are national security implications to advanced compute capabilities
- The US has shown interest in controlling access to advanced technologies in international contexts (via export controls)

**Key differences:**
- Compute is fundamentally digital rather than physical, making it harder to track, measure, and control
- Compute is far more general-purpose than previously regulated technologies
- The technology is controlled by some of the largest and most influential corporations in the world
- Compute is central to current geopolitical competition with China
- There has been no catastrophic incident (like nuclear accidents) to catalyze regulatory action
- The pace of AI development is much faster than previous regulated technologies

These differences generally suggest an even lower probability than the base rate, as the barriers to regulation are higher.

## 3. Evidence Evaluation (Likelihoods)

Let's evaluate key pieces of evidence:

**Evidence 1: Continued reliance on export controls rather than domestic limits**
- P(E|H): If the US were planning to implement domestic compute restrictions, we would expect to see a shift away from export controls as the primary policy tool. Moderate likelihood (~0.3)
- P(E|~H): If the US were not planning domestic restrictions, we would expect continued focus on export controls. High likelihood (~0.9)
- Likelihood ratio: 0.3/0.9 = 0.33 (evidence against domestic restrictions)

**Evidence 2: Legislative proposals focusing on application/liability, not compute**
- P(E|H): If domestic compute restrictions were coming, we would expect to see draft legislation mentioning compute caps. Low likelihood (~0.2)
- P(E|~H): If no restrictions were coming, we would expect legislation to focus on other aspects of AI regulation. High likelihood (~0.9)
- Likelihood ratio: 0.2/0.9 = 0.22 (strong evidence against restrictions)

**Evidence 3: Solidification of a "report, don't restrict" regime via NIST rules**
- P(E|H): If compute restrictions were imminent, reporting requirements would likely be a precursor. Moderate likelihood (~0.5)
- P(E|~H): If no restrictions were planned, reporting requirements alone would be the preferred approach. High likelihood (~0.9)
- Likelihood ratio: 0.5/0.9 = 0.56 (moderate evidence against restrictions)

**Evidence 4: Strong, unified industry and national security opposition**
- P(E|H): If restrictions were coming, we would expect to see less unified opposition. Low likelihood (~0.2)
- P(E|~H): If no restrictions were coming, we would expect strong opposition to prevent them. High likelihood (~0.9)
- Likelihood ratio: 0.2/0.9 = 0.22 (strong evidence against restrictions)

**Evidence 5: Absence of a catalyzing crisis event**
- P(E|H): If restrictions were coming, we would likely have seen a major AI-related incident. Very low likelihood (~0.1)
- P(E|~H): If no restrictions were coming, the absence of a crisis is expected. High likelihood (~0.9)
- Likelihood ratio: 0.1/0.9 = 0.11 (very strong evidence against restrictions)

## 4. Bayesian Updating (Posterior Probability)

Starting with our prior of 5% (odds of 1:19), let's update based on the evidence:

Posterior odds = Prior odds × Likelihood ratio
Posterior odds = (1/19) × 0.33 × 0.22 × 0.56 × 0.22 × 0.11
Posterior odds = (1/19) × 0.00093
Posterior odds ≈ 0.000049

Converting back to probability:
Posterior probability = Posterior odds / (1 + Posterior odds)
Posterior probability ≈ 0.000049 / 1.000049
Posterior probability ≈ 0.0049%

This extremely low probability seems unreasonable given the complexity of the situation. Let's be more conservative and consider that our evidence points may be correlated and that we might be overconfident in our likelihood ratios. A more reasonable approach would be to apply a single composite likelihood ratio.

Composite likelihood ratio ≈ 0.15 (representing strong but not overwhelming evidence against)

Posterior odds = (1/19) × 0.15 ≈ 0.0079
Posterior probability ≈ 0.0079 / 1.0079 ≈ 0.78%

## 5. Red Team Thinking

**Potential blind spots:**
- I may be underestimating the possibility of a sudden, catastrophic AI incident that could dramatically change the political calculus
- Executive action could bypass the legislative process, allowing for faster implementation of restrictions
- The definition of "restrictions" could be broader than I'm considering (e.g., heavy taxes or burdensome reporting requirements that effectively limit compute)
- International coordination could make domestic restrictions more palatable by reducing competitive disadvantages

**Alternative scenarios:**
- A major AI safety incident occurs in early 2025, creating a policy window for emergency measures
- Bipartisan concern about AI risks grows rapidly, leading to fast-tracked legislation
- The President uses executive powers to impose temporary restrictions that remain in place through 2025

**Adjustments:**
Given these considerations, I should adjust my probability upward slightly to account for these tail risks and alternative pathways. The Manifold market shows a community forecast of 1.5%, which is higher than my calculated posterior but still very low.

## 6. Final Forecast

After considering the base rate, the specific evidence, and potential blind spots, I believe the probability of the US placing restrictions on total compute capacity for individuals or companies before 2026 is very low. The legislative timeline is too short, the political and economic headwinds are immense, and the established policy approach focuses on export controls rather than domestic possession limits.

Only an unforeseen, catastrophic AI event could likely create the political will for such a radical policy shift before 2026, and even then, implementation challenges would be substantial.

Final: 2%

```

#### Gemini

- ok=True | t_ms=51909 | tokens: prompt=4279, completion=1535, total=9854 | cost=$0.020699

```md

### 1. Base Rate (Prior) Selection
The most appropriate reference class is the historical frequency of the US government imposing *domestic possession limits* on a broadly useful, dual-use technology. This is a very rare type of regulation. Historical examples are limited to technologies with clear and direct weaponization potential, such as fissile materials (Atomic Energy Act) or specific biological agents (Select Agent Program). Compute, being a general-purpose technology essential for the entire economy, fits poorly into this category. The historical frequency of such a law being enacted for a new general-purpose technology within a few years of its emergence is extremely low.
- **Base Rate (Prior):** I will set the prior probability at **3%**. This reflects the exceptional nature of such a policy, while acknowledging that the unprecedented capabilities of AI could motivate novel regulatory approaches.

### 2. Comparison to Base Case
- **Similarities:** Like nuclear materials, advanced AI is seen by some as a technology with potential for catastrophic risks, justifying strong government oversight.
- **Differences:**
    - **Economic Centrality:** Unlike fissile materials, compute is a foundational resource for the modern economy. Restricting it would have vast, negative economic consequences, creating immense opposition.
    - **Geopolitical Context:** The US is in a widely acknowledged "AI race" with China. Unilaterally restricting domestic compute would be framed as ceding leadership to a strategic rival, a powerful argument against such a policy.
    - **Nature of Harm:** The harms from AI are, at present, more abstract and theoretical than the concrete, physical threat of a nuclear weapon. Without a clear, undeniable "smoking gun" incident, it is difficult to build the political consensus needed for such a radical law.
    - **Lobbying Power:** The technology is controlled by some of the world's largest and most influential corporations, whose lobbying power against such restrictions is immense.

These differences strongly suggest that restricting compute is even less likely than the historical base rate for other powerful technologies would imply.

### 3. Evidence Evaluation
The research report provides several key pieces of evidence, all of which point towards a lower probability.

- **Evidence 1: Focus on Export Controls (e.g., 2025-10-15 rule).** The US government's consistent policy choice has been to restrict adversaries' access to advanced chips, not to limit domestic capacity. This shows the dominant policy frame is geopolitical competition, not domestic risk mitigation. This evidence makes the "NO" outcome much more likely. (P(E|~H) >> P(E|H)). **Decreases probability.**
- **Evidence 2: Legislative Proposals Omit Compute Caps (e.g., 2025-09-22 draft bill).** The current legislative conversation centers on liability, auditing, and transparency. The absence of compute caps in serious proposals indicates it is outside the current Overton window of plausible policy. (P(E|~H) > P(E|H)). **Decreases probability.**
- **Evidence 3: Establishment of a "Monitoring" Regime (e.g., 2025-06-04 NIST rules).** The implementation of the AI Executive Order created a requirement for companies to *report* large training runs, not to *limit* them. This establishes a clear, less restrictive regulatory path, making a sudden pivot to hard caps less likely. This is strong evidence for "NO". (P(E|~H) >> P(E|H)). **Strongly decreases probability.**
- **Evidence 4: Unified Industry Opposition (e.g., 2025-07-10 testimony).** The powerful tech lobby is united against domestic restrictions, effectively framing them as a threat to American innovation and national security. (P(E|~H) > P(E|H)). **Decreases probability.**

The cumulative effect of this evidence is a strong update downwards from the already low prior.

### 4. Bayesian Updating (Posterior Probability)
- **Prior Odds:** A 3% probability corresponds to prior odds of 0.03 / 0.97 ≈ 1-to-32.
- **Likelihood Update:** The evidence, particularly the establishment of an alternative regulatory regime (monitoring) and the consistent focus on export controls, strongly favors the "NO" hypothesis. A combined likelihood ratio of 0.2 (i.e., this evidence is 5 times more likely if no caps are planned) seems conservative.
- **Posterior Odds:** Prior Odds × Likelihood Ratio ≈ (1/32) × 0.2 = 0.00625.
- **Posterior Probability:** Odds / (1 + Odds) ≈ 0.00625 / 1.00625 ≈ 0.62%.

This calculation suggests a probability below 1%. The short timeline (less than 14 months until the end of 2025) further constrains the likelihood, as passing such complex and controversial legislation is a multi-year process.

### 5. Red Team Thinking
The primary reason my forecast could be wrong is a "black swan" event: a sudden, unambiguous, and catastrophic incident caused by an AI system. Such an event could shatter the existing political calculus and create a policy window for radical action, bypassing normal legislative inertia. For example, a President might use emergency powers to impose restrictions via Executive Order.

Let's model this:
- P(Catastrophe): The probability of an AI-caused disaster sufficient to trigger this response before 2026. This is low, perhaps 1.5%.
- P(Caps | Catastrophe): Even if a disaster occurs, compute caps are just one possible response. Others include nationalization of labs or strict liability laws. The probability of this specific response might be 30%.
- P(Caps | No Catastrophe): This is the probability from my main analysis, which is very low, around 0.5%.

P(Caps) = P(Caps | Catastrophe) * P(Catastrophe) + P(Caps | No Catastrophe) * P(No Catastrophe)
P(Caps) ≈ (0.30 * 0.015) + (0.005 * 0.985) ≈ 0.0045 + 0.0049 ≈ 0.0094 or 0.94%.

This structured consideration of the primary failure mode confirms that the probability remains very low, around 1%. The forecast is highly dependent on the "no catastrophe" scenario, which is the overwhelming default.

### 6. Final Forecast
The base rate for this type of regulation is extremely low. The specific context of geopolitical competition with China and the immense economic importance of the AI industry provide powerful headwinds against such a policy. Recent government actions have established a clear alternative path of export controls and domestic monitoring, not caps. The timeline is too short for such a landmark law to pass under normal conditions. The only plausible path to a "YES" resolution is a catastrophic AI incident, which is a low-probability tail risk. Combining these factors leads to a very low final probability.

Final: 1%

```

#### Grok

- ok=False | t_ms=308 | tokens: prompt=0, completion=0, total=0 | cost=$0.000000

- error=HTTP 429: Your team 0101076a-72f1-4f25-a038-b346d74bbc8d has either used all available credits or reached its monthly spending limit. To continue making API requests, please purchase more credits or raise your spending limit.

### Aggregation (BMC)

- final_probability=0.0444

- bmc_summary={"mean": 0.04439692806868007, "p10": 1.9332000188174498e-08, "p50": 0.0018183871338458616, "p90": 0.14657393349931616}