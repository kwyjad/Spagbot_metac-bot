# Will the US or California require licenses to train large AI models before 2026? (QID: 38854)

- Type: binary

- URL: https://www.metaculus.com/questions/38854/

- Classifier: technology | strategic=False (score=0.00)

### SeenGuard

- enabled=True | lock_status=acquired

- run_filter: before=2 | skipped=0 | after=2

- debug_note=lock acquired

## Research (summary)

CALIBRATION GUIDANCE (auto-generated weekly):
BINARY CALIBRATION
- No resolved binary questions (with pre-resolution forecasts) yet.
- Advice: keep using base rates + small evidence-weighted updates; avoid big swings.

MULTIPLE-CHOICE CALIBRATION (Top-1)
- No resolved MCQ questions (with pre-resolution forecasts) yet.

NUMERIC CALIBRATION (PIT-lite + CRPS)
- No resolved numeric questions (with pre-resolution forecasts) yet.
- When numeric results exist, we’ll check p10/p50/p90 coverage and CRPS.

General takeaway: apply **small** nudges only where gaps are consistent with decent sample sizes (≥10).
— end calibration —

### Reference class & base rates
1.  **Major New Federal Technology Regulation:** This class includes the creation of new regulatory bodies or sweeping legislation for novel technologies (e.g., Federal Aviation Administration for air travel, Nuclear Regulatory Commission for nuclear power, Communications Decency Act for the internet). Historically, such frameworks take many years, often 5-10+, from the technology's emergence to the implementation of a licensing regime. The base rate of a comprehensive licensing law being passed and taking effect within three years of a technology's "mainstream moment" (e.g., ChatGPT's launch in late 2022) is very low, likely **<5%**.
2.  **State-Level Tech Regulation (California Precedent):** California often acts as a regulatory first-mover in the US, particularly on tech and environmental issues (e.g., California Consumer Privacy Act - CCPA, vehicle emissions standards). These processes are faster than federal ones but still deliberate. The CCPA was passed in 2018 and became effective in 2020. This suggests a 2-3 year timeline is plausible. The base rate for California enacting and implementing a novel tech licensing regime within three years is significantly higher, perhaps in the **20-30% range**.
3.  **Rapid Regulation Following a Crisis:** This class includes legislation passed swiftly in response to a major disaster or perceived national security threat (e.g., The Patriot Act after 9/11). Such regulation can be enacted and implemented in under a year. This is a conditional base rate; it requires a triggering event. The unconditional probability is low, but if a major AI-related catastrophe were to occur, the probability of emergency legislation would become very high.

### Recent developments (timeline bullets)
*   [2025-10-22] Lawfare article proposes a shared liability regime for AI firms. (↑) — Shows that sophisticated policy proposals beyond simple licensing are being actively discussed, indicating a mature and urgent policy environment.
*   [2025-10-21] California enacts SB 53, the Transparency in Frontier Artificial Intelligence Act (TFAIA). (↑) — A landmark event. The first US state has passed a law specifically governing frontier AI, demonstrating that legislative action is possible.
*   [2025-10-21] Implementation date for California's SB 53 is set for January 2026. (↓↓) — This is the most critical fact. While a law has passed, its requirements do not take effect until *after* this question's resolution date of Dec 31, 2025.
*   [2025-06-16] Sam Altman predicts AI will make "novel insights" by 2026. (↑) — Reinforces the narrative of rapidly accelerating capabilities, which increases the perceived urgency for regulation among policymakers.
*   [2025-06-03] At Snowflake Summit, Altman reiterates his 2026 prediction for AI-driven scientific discovery. (↑) — Keeps the pressure on by highlighting the imminent arrival of more powerful, potentially unpredictable systems.

### Mechanisms & drivers (causal levers)
1.  **Legislative Inertia & Timelines (Large ↓):** The US and California legislative calendars are the most powerful drivers for NO. With today's date being Oct 28, 2025, there is virtually no time for a new bill to be introduced, debated, passed, and signed into law before the Dec 31, 2025 deadline. California's legislative session for 2025 is over.
2.  **AI-Related Catastrophe (Large ↑):** A "black swan" event, such as a large-scale cyberattack, a critical infrastructure failure, or a mass disinformation campaign demonstrably caused by a frontier model, could trigger emergency legislative or executive action, overriding normal timelines.
3.  **Implementation of Existing Law (Large ↓):** The key development, California's SB 53, has an implementation date of January 2026. This directly prevents a YES resolution from the most likely source (California) unless the date is moved up, which is exceptionally rare.
4.  **Executive Action (Moderate ↑):** The White House could attempt to use existing authority (e.g., via the Commerce Department or NIST under the 2023 AI Executive Order) to institute a *de facto* licensing or registration scheme. This is a plausible but legally contentious pathway that would likely face immediate court challenges.
5.  **Industry Lobbying (Moderate ↑/↓):** While some labs (OpenAI, Anthropic) have called for licensing (pro-moat regulation), other parts of the tech industry (VCs, open-source advocates) lobby against it to prevent stifling innovation. This creates a divided, complex political landscape that favors inaction.

### Differences vs. the base rate (what’s unusual now)
*   **Pro-Regulation Industry Actors:** Unlike most historical examples where industry uniformly fought regulation, key AI developers like OpenAI and Anthropic have actively called for a licensing regime. This is a significant departure from the norm and accelerates policy conversations.
*   **Pace of Technological Change:** AI capabilities are advancing at a rate far exceeding that of previous regulated technologies (e.g., aviation, nuclear power). This creates immense pressure on slow-moving legislative bodies, potentially forcing them to act faster or in novel ways.
*   **Geopolitical Competition:** The intense AI race with China creates a powerful counter-narrative against regulation. Arguments that licensing would cede the US's technological lead carry significant weight, a factor not as prominent in, for example, the passage of consumer privacy laws.
*   **Existing Legislative Success:** The passage of California's SB 53 demonstrates that the political will to regulate AI exists and can overcome legislative hurdles. The base rate for *passing a law* has been met; the issue is now purely one of timing and implementation.

### Bayesian update sketch (for the statistician)
*   **Prior:** Based on the California state-level reference class, a prior of ~25% (with an equivalent n=10) seems appropriate. This acknowledges CA's tendency to regulate but also the difficulty of creating a novel licensing regime.
*   **Evidence mapping:**
    *   (↑ Large) California has successfully passed SB 53, a comprehensive frontier AI governance law, proving it is politically feasible.
    *   (↓↓ Decisive) The implementation date for SB 53 is explicitly set for January 2026, after the resolution period. This is a direct, powerful piece of negative evidence.
    *   (↓ Moderate) The federal legislative calendar for 2025 is effectively closed, making a new federal law impossible.
    *   (↑ Small) The ongoing high-stakes conversation about AI risk and capability keeps the issue salient, creating a small possibility of unexpected executive action.
*   **Net effect:** The evidence overwhelmingly points downward. The passage of SB 53 was a strong positive update, but its post-deadline implementation date is a near-fatal blow to a "YES" resolution. The posterior should be revised sharply down, likely into the very low single digits.

### Indicators to watch (leading signals; next weeks/months)
*   **UP indicators:**
    *   A major, undeniable AI-caused public disaster.
    *   The White House announcing a new Executive Order that uses emergency powers or existing authority to mandate pre-training registration.
    *   California's governor calling a special legislative session to amend SB 53 and accelerate its implementation date (extremely unlikely).
    *   A major federal agency (e.g., Commerce, FTC) issuing an emergency rule-making notice related to AI model training.
*   **DOWN indicators:**
    *   Official adjournment of the U.S. Congress for the 2025 holiday recess with no AI bill passed.
    *   Statements from California officials confirming the January 2026 implementation timeline for SB 53.
    *   Major AI labs announcing new model releases without any mention of new licensing or registration requirements.

### Caveats & pitfalls
*   **Definitional Ambiguity:** The term "license or permit of some type" is broad. A creative interpretation of an executive order's registration requirement could potentially satisfy the criteria, even if it's not a formal "license."
*   **Implementation vs. Enactment:** The forecast hinges on the distinction between a law being *on the books* (enacted) versus its requirements being legally *in force* (implemented). The resolution criteria imply the latter.
*   **"Black Swan" Risk:** The forecast assumes no catastrophic AI incidents in the next two months. Such an event would invalidate the current political and legislative assumptions.
*   **State vs. Federal Action:** While focus is on California and the US Congress, a federal agency could act independently, though its authority to create a full licensing regime without new legislation

Market snapshot debug:
- Metaculus: no open binary results in response
- Manifold: best score 0.50 below threshold 0.55 for 'Will the US require purchasers of large numbers of GPUs to report their usage before 2026?'

### Sources
- Sam Altman just dropped a big AI prediction for 2026; experts are skeptical (timesofindia.indiatimes.com) — https://timesofindia.indiatimes.com/gadgets-news/sam-altman-just-dropped-a-big-ai-prediction-for-2026-experts-are-skeptical/articleshow/110993332.cms
- ChatGPT creator Sam Altman testifies in Congress about AI risks (www.latimes.com) — https://www.latimes.com/business/story/2023-05-16/chat-gpt-creator-sam-altman-testifies-in-congress-about-ai-risks
- The UK AI Safety Summit Opened a New Chapter in AI Diplomacy (carnegieendowment.org) — https://carnegieendowment.org/2023/11/09/uk-ai-safety-summit-opened-new-chapter-in-ai-diplomacy-pub-91001
- Shared Residual Liability for Frontier AI Firms (www.lawfaremedia.org) — https://www.lawfaremedia.org/article/shared-residual-liability-for-frontier-ai-firms
- Governing Frontier AI: California's SB 53 (www.lawfaremedia.org) — https://www.lawfaremedia.org/article/governing-frontier-ai-california-s-sb-53
- Sam Altman Predicts AI Will Discover New Knowledge by 2026 — OpenAI CEO at Snowflake Summit (www.youtube.com) — https://www.youtube.com/watch?v=s2x-h_b-o-M
- Sam Altman Just Revealed What's Coming in 2025, 2026 & 2027 (www.youtube.com) — https://www.youtube.com/watch?v=0Qj96T3j-wA
- Sam Altman's Prediction: 2026 - AI Discovers New Knowledge, 2027 - Robot Uprising, 2030 - Infinite Intelligence! (www.aibase.com) — https://www.aibase.com/news/sam-altmans-prediction-2026-ai-discovers-new-knowledge-2027-robot-uprising-2030-infinite-intelligence/

### Research (debug)

- source=GoogleGrounding | llm=google/gemini-2.5-pro | cached=0 | n_raw=11 | n_kept=8 | cost=$0.025026

- query: format; metac_closes_in_period; info; post_id; question_id; Sam Altman; Frontier AI; 2026; 2025; 2023

### GTMC1 (debug)

- strategic_class=False | strategic_score=0.00 | source=llm

- gtmc1_active=False | qtype=binary | t_ms=0

- actors_parsed=0

- exceedance_ge_50=None | coalition_rate=None | median=None | dispersion=None

### Ensemble (model outputs)

- OpenRouter-Default: ok=True t_ms=21961 p=0.0200

- Claude-3.7-Sonnet (OR): ok=True t_ms=28998 p=0.0100

- Gemini: ok=True t_ms=48561 p=0.0400

- Grok: ok=False t_ms=272



### Per-model (raw + usage/cost)

#### OpenRouter-Default

- ok=True | t_ms=21961 | tokens: prompt=3583, completion=643, total=4226 | cost=$0.015388

```md

To forecast the probability of the US or California requiring licenses to train large AI models before 2026, we will follow a structured Bayesian reasoning approach.

1. **Base Rate (Prior) Selection**
   - **Federal Regulation Base Rate:** Historically, major new federal technology regulations take 5-10+ years to implement. Given the timeline from ChatGPT's launch in late 2022, the base rate for a comprehensive federal licensing law being passed and taking effect by 2026 is very low, likely <5%.
   - **California State Regulation Base Rate:** California has a history of being a regulatory first-mover, with a plausible 2-3 year timeline for enacting and implementing new tech regulations. The base rate for California enacting such a regime within three years is higher, around 20-30%.
   - **Selected Prior:** Given the focus on California and its recent legislative actions, a prior probability of 25% is reasonable, reflecting California's regulatory tendencies.

2. **Comparison to Base Case**
   - **Similarities:** California has shown a willingness to regulate AI, as evidenced by the passage of SB 53. This aligns with the base case of California being proactive in tech regulation.
   - **Differences:** The implementation date for SB 53 is set for January 2026, which is after the resolution date. This is a critical difference that significantly impacts the probability.

3. **Evidence Evaluation (Likelihoods)**
   - **California's SB 53 Passage (↑):** The passage of SB 53 indicates political feasibility and willingness to regulate AI, increasing the probability.
   - **SB 53 Implementation Date (↓↓):** The implementation date of January 2026 is after the resolution period, strongly decreasing the probability.
   - **Federal Legislative Calendar (↓):** The federal legislative calendar for 2025 is effectively closed, making new federal legislation unlikely.
   - **Executive Action Possibility (↑):** There is a small chance of executive action, but it is legally contentious and would likely face challenges.

4. **Bayesian Updating (Posterior Probability)**
   - **Prior Odds:** 25% probability translates to odds of 1:3.
   - **Likelihood Ratio:** The decisive evidence of SB 53's implementation date being post-deadline heavily outweighs other factors.
   - **Posterior Odds Calculation:** Given the strong negative evidence, the posterior probability should be revised sharply downward, likely into the very low single digits.

5. **Red Team Thinking**
   - **Overconfidence Check:** The forecast assumes no major AI-related catastrophe, which could change the landscape. However, the likelihood of such an event in the next two months is low.
   - **Alternative Scenarios:** A federal agency could attempt emergency rule-making, but this is unlikely to meet the resolution criteria.
   - **Adjustment Consideration:** Given the strong negative evidence, the probability remains low despite considering alternative scenarios.

6. **Final Forecast**
   - The final probability reflects the base rate, the impact of SB 53's implementation date, and the low likelihood of alternative scenarios leading to a YES resolution.

Final: 2%

```

#### Claude-3.7-Sonnet (OR)

- ok=True | t_ms=28998 | tokens: prompt=4076, completion=1561, total=5637 | cost=$0.035643

```md

# Will the US or California require licenses to train large AI models before 2026?

## 1. Base Rate (Prior) Selection

For this question, I need to identify an appropriate reference class of similar regulatory actions. The most relevant reference classes are:

1. **State-level technology regulation in California**: California often leads in tech regulation, with examples like the California Consumer Privacy Act (CCPA). These typically take 2-3 years from proposal to implementation.

2. **Federal technology licensing regimes**: Examples include nuclear power regulation, pharmaceutical approval processes, and aviation licensing. These typically take 5-10+ years to establish.

Given that we're looking at either California OR federal action by the end of 2025, and considering California's faster regulatory pace, I'll use a weighted prior that leans toward the California reference class.

**Prior probability: 25%**

This reflects:
- California's history as a regulatory first-mover
- The significant but not overwhelming political momentum for AI regulation
- The typical timeline for establishing new regulatory frameworks
- The "OR" condition that allows either federal or state action to satisfy the criteria

## 2. Comparison to Base Case

**Similarities to base case:**
- Like other emerging technologies, AI is generating public concern and calls for oversight
- The regulatory process follows similar legislative and administrative procedures
- Industry stakeholders have significant influence on the regulatory outcome
- California remains a tech regulatory leader

**Key differences:**
- Some major AI companies (OpenAI, Anthropic) have actively called for licensing, unlike typical industry resistance
- AI development is advancing extremely rapidly compared to historical technologies
- The geopolitical competition with China creates countervailing pressure against regulation
- California has already passed SB 53 (Transparency in Frontier Artificial Intelligence Act), but with implementation set for January 2026

## 3. Evidence Evaluation

**Evidence 1: California has passed SB 53 with implementation in January 2026**
- P(E|H): Very high (~0.9) - If licensing were to be required before 2026, California passing a related law would be expected
- P(E|~H): Moderate (~0.4) - Even if licensing isn't required before 2026, California might still pass such a law for later implementation
- Likelihood ratio: ~2.25
- **Direction: Slightly positive for YES, but the January 2026 implementation date is a critical negative factor**

**Evidence 2: Current legislative calendar constraints**
- P(E|H): Very low (~0.1) - If licensing were to happen before 2026, we would not expect to see such tight calendar constraints
- P(E|~H): Very high (~0.9) - If licensing won't happen before 2026, the current calendar constraints would be expected
- Likelihood ratio: ~0.11
- **Direction: Strongly negative for YES**

**Evidence 3: Industry leaders like Sam Altman calling for licensing**
- P(E|H): High (~0.8) - If licensing were to happen, we'd expect industry support
- P(E|~H): Moderate (~0.4) - Even without licensing, some industry leaders might call for it
- Likelihood ratio: ~2.0
- **Direction: Positive for YES**

**Evidence 4: Absence of major AI catastrophes to date**
- P(E|H): Moderate (~0.5) - Licensing could happen with or without catastrophes
- P(E|~H): High (~0.8) - Without catastrophes, licensing is less likely
- Likelihood ratio: ~0.63
- **Direction: Negative for YES**

## 4. Bayesian Updating

Starting with prior odds of 25:75 (1:3)

**Update on California's SB 53 with January 2026 implementation:**
- Prior odds: 1:3
- Likelihood ratio: ~0.1 (adjusting downward from 2.25 due to the critical January 2026 date)
- Posterior odds: 1:3 × 0.1 = 0.1:3 = 1:30
- Posterior probability: 1/(1+30) ≈ 3.2%

**Update on legislative calendar constraints:**
- Prior odds: 1:30
- Likelihood ratio: 0.11
- Posterior odds: 1:30 × 0.11 = 0.11:30 ≈ 1:273
- Posterior probability: 1/(1+273) ≈ 0.37%

**Update on industry support for licensing:**
- Prior odds: 1:273
- Likelihood ratio: 2.0
- Posterior odds: 1:273 × 2.0 = 2:273 ≈ 1:136.5
- Posterior probability: 1/(1+136.5) ≈ 0.73%

**Update on absence of major AI catastrophes:**
- Prior odds: 1:136.5
- Likelihood ratio: 0.63
- Posterior odds: 1:136.5 × 0.63 = 0.63:136.5 ≈ 1:217
- Posterior probability: 1/(1+217) ≈ 0.46%

## 5. Red Team Thinking

**Potential blind spots:**
- I may be underestimating the possibility of emergency executive action
- The definition of "license or permit" could be interpreted broadly
- A major AI incident in the next two months could dramatically change the landscape
- Federal agencies might use existing authority to implement a de facto licensing regime

**Alternative scenarios:**
- The White House could issue an emergency executive order requiring registration before training
- California could theoretically accelerate SB 53's implementation date through emergency action
- A federal agency like NIST or the Commerce Department could establish a mandatory registration system under existing authority

**Adjustments:**
Given these considerations, I should adjust my estimate slightly upward to account for these low-probability but plausible pathways. However, the adjustment should be modest given the overwhelming evidence against a YES resolution, particularly the explicit January 2026 implementation date for California's SB 53.

## 6. Final Forecast

The evidence overwhelmingly points to a very low probability of either the US or California requiring licenses to train large AI models before December 31, 2025:

1. California has already passed relevant legislation (SB 53), but explicitly set implementation for January 2026
2. The legislative calendar makes new federal legislation virtually impossible before year-end
3. Executive action remains a possibility but faces significant legal and practical hurdles
4. The absence of a major AI catastrophe reduces urgency for emergency measures

Accounting for all evidence and potential blind spots, I arrive at a final probability of approximately 1%.

Final: 1%

```

#### Gemini

- ok=True | t_ms=48561 | tokens: prompt=3931, completion=1452, total=9151 | cost=$0.019434

```md

### 1. Base Rate (Prior) Selection
The most appropriate reference class is the enactment of novel, state-level technology regulation in California. California is often a regulatory first-mover in the US (e.g., California Consumer Privacy Act - CCPA, vehicle emissions standards). The CCPA was passed in 2018 and became effective in 2020, a roughly two-year process. The question asks about a licensing regime being required before 2026, roughly three years after the "mainstream moment" of generative AI with ChatGPT's launch in late 2022. A 2-3 year timeline for a complex new regulatory regime like this is ambitious but plausible for California. Therefore, a reasonable prior probability, set at the beginning of the period, would be around **25%**. This acknowledges California's proactive stance while respecting the inherent difficulty and slowness of the legislative process.

Prior Odds: 0.25 / (1 - 0.25) = 1:3.

### 2. Comparison to Base Case
**Similarities:**
- The issue of AI safety and governance is a high-profile topic of public and political debate, similar to data privacy which spurred the CCPA.
- The industry is heavily concentrated in California, making state-level action highly impactful.

**Differences:**
- **Pro-Regulation Industry Actors:** Unusually, major AI labs like OpenAI have publicly called for licensing, potentially accelerating the political process. This is a significant departure from the typical industry-wide opposition to regulation.
- **Legislative Timeline:** The most crucial difference is the current date. The provided context places us at **October 28, 2025**. With only two months left until the December 31, 2025 deadline, the normal legislative process is no longer a viable path for any *new* law.

### 3. Evidence Evaluation (Likelihoods)
The analysis is dominated by the short time remaining and recent legislative events.

*   **Evidence 1: California passed SB 53, the Transparency in Frontier Artificial Intelligence Act (TFAIA), on October 21, 2025.**
    *   This is strong evidence that the political will to regulate AI exists and can succeed.
    *   P(E | H): If a license were required by 2026 (H), it is very likely that a law would have been passed. This evidence supports H.
    *   Likelihood Ratio: > 1 (Increases probability).

*   **Evidence 2: The implementation date for SB 53 is January 2026.**
    *   This is the most decisive piece of evidence. The law's requirements will not be in force until *after* the question's resolution date.
    *   P(E | H): The probability of the implementation date being *after* the deadline, given that a license *is* required before the deadline, is nearly zero.
    *   P(E | ~H): The probability of the implementation date being after the deadline, given that a license is *not* required before the deadline, is very high. This is precisely the state of affairs we would expect for a "NO" resolution.
    *   Likelihood Ratio: << 1 (Drastically decreases probability). This evidence almost single-handedly resolves the question against H, barring an extraordinary event.

*   **Evidence 3: The 2025 legislative sessions for both the US Congress and California are effectively over.**
    *   This closes the door on any *new* legislation being passed and implemented before the deadline.
    *   Likelihood Ratio: << 1 (Strongly decreases probability).

### 4. Bayesian Updating (Posterior Probability)
We start with prior odds of 1:3 (a 25% probability). The evidence that the main legislative vehicle (SB 53) has passed but will not take effect in time is a near-fatal blow to the "YES" case.

Let's update based on the implementation date of SB 53.
*   Prior Odds: 1:3
*   Likelihood Ratio for Jan 2026 implementation date: Extremely small (e.g., 1/100), as it makes a "YES" resolution via this path impossible.
*   Posterior Odds ≈ (1:3) * (1/100) = 1:300
*   Posterior Probability ≈ 1 / (1 + 300) ≈ 0.3%

This calculation shows that the legislative path is closed. The only remaining possibility for a "YES" resolution is a non-legislative action, such as an emergency Executive Order or a new binding rule from a federal agency.

### 5. Red Team Thinking
My forecast is very low. What could make it wrong?
The primary blind spot is underestimating the potential for swift executive action. The question's wording, "license or permit of some type," is broad. A White House Executive Order or a Department of Commerce rule, citing national security under the Defense Production Act or the AI Executive Order of 2023, could mandate a "registration" or "pre-approval" for training runs. This could be plausibly interpreted as a "permit."

An alternative forecast of 10-15% would argue that a major AI-related incident (e.g., a large-scale disinformation event) could trigger such an emergency action in the final two months of 2025. This is a tail risk, but not an impossible one.

However, even this path is difficult. Such an order would face immediate legal challenges for executive overreach, and the administrative process for implementing a new, binding rule typically takes more than two months. The path of least resistance for the government is to wait for California's SB 53 to come into effect in January 2026.

Therefore, while the risk of executive action is real, its probability remains low. I will adjust my posterior slightly upward from the sub-1% calculated to account for this specific, non-legislative risk. A probability of 4% seems appropriate, acknowledging the path is highly unlikely but not impossible.

### 6. Final Forecast
The legislative pathways for requiring an AI training license in the US or California before 2026 are now closed. California has passed a relevant law, SB 53, but its implementation is explicitly set for January 2026, after the resolution date. The only remaining, low-probability path for a "YES" resolution is an emergency executive action or a new, rapidly implemented federal agency rule. The likelihood of such an action being taken and becoming effective in the next two months is very small.

Final: 4%

```

#### Grok

- ok=False | t_ms=272 | tokens: prompt=0, completion=0, total=0 | cost=$0.000000

- error=HTTP 429: Your team 0101076a-72f1-4f25-a038-b346d74bbc8d has either used all available credits or reached its monthly spending limit. To continue making API requests, please purchase more credits or raise your spending limit.

### Aggregation (BMC)

- final_probability=0.0536

- bmc_summary={"mean": 0.05357830456689667, "p10": 3.3233416280516874e-07, "p50": 0.004321282442158543, "p90": 0.17662174375129083}