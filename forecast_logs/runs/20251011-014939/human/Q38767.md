# What will be the best score by an AI on the full Humanity's Last Exam (HLE) before 2026? (QID: 38767)

- Type: numeric

- URL: https://www.metaculus.com/questions/38767/

- Classifier: technology | strategic=False (score=0.00)

### SeenGuard

- enabled=True | lock_status=acquired

- run_filter: before=2 | skipped=0 | after=2

- debug_note=lock acquired

## Research (summary)

CALIBRATION GUIDANCE (auto-generated weekly):
BINARY CALIBRATION
- No resolved binary questions (with pre-resolution forecasts) yet.
- Advice: keep using base rates + small evidence-weighted updates; avoid big swings.

MULTIPLE-CHOICE CALIBRATION (Top-1)
- No resolved MCQ questions (with pre-resolution forecasts) yet.

NUMERIC CALIBRATION (PIT-lite + CRPS)
- No resolved numeric questions (with pre-resolution forecasts) yet.
- When numeric results exist, we’ll check p10/p50/p90 coverage and CRPS.

General takeaway: apply **small** nudges only where gaps are consistent with decent sample sizes (≥10).
— end calibration —

### Reference class & base rates
1.  **SOTA Improvement on New, Difficult Benchmarks (First ~15 months):** When a new, challenging benchmark is introduced, initial progress is often rapid before slowing.
    *   **MMLU (Massive Multitask Language Understanding):** Introduced in 2020. Early models scored near random (25%). GPT-3 (2020) scored ~44%. By early 2023, GPT-4 achieved 86.4%, a ~42 percentage point gain in ~2.5 years. The first year saw a jump of ~20 points.
    *   **MATH (Hendrycks et al.):** Introduced in 2021. Early models scored in the single digits. GPT-4 (2023) scored 52.9%. Later, specialized models (e.g., with tool use/search) pushed this into the 80s and 90s. The initial jump for a general model was significant but left substantial room for improvement.
    *   **Base Rate:** A 15-30 percentage point improvement over the initial non-trivial score within the first 12-18 months is a plausible base rate. HLE's initial SOTA is 26.6%. Applying this base rate over a full year would suggest a score in the range of 41.6% to 56.6%. However, our horizon is only ~2.5 months. A linear interpolation suggests a much smaller gain of **3-6 percentage points**.
2.  **Pace of "Point-Release" Model Improvements:** Major labs often release incremental updates between flagship models (e.g., GPT-3 to 3.5, Gemini 1.0 to 1.5). These updates typically yield smaller but significant gains on key benchmarks.
    *   **Base Rate:** These incremental releases often produce gains of **5-10 percentage points** on difficult reasoning benchmarks over a 6-9 month period. This serves as a lower-bound estimate for progress driven by continuous improvement rather than architectural breakthroughs.

### Recent developments (timeline bullets)
*   **2025-10-09** Unveiling the Future of AGI article published — ↓ — Article reflects a more conservative expert consensus (AGI in 2040-2060), suggesting fundamental hurdles remain that might slow progress on frontier benchmarks like HLE.
*   **2025-09-28** Google DeepMind releases technical blog on "Compositional Reasoning Fusion" — ↑ — A new technique shows a 7% relative improvement on complex multi-modal science questions. This algorithmic gain could directly apply to HLE-style problems.
*   **2025-09-16** The AGI Revolution article published — ↑ — Highlights bullish AGI timelines from key lab leaders (Amodei: "powerful general AI by 2026"). This sentiment suggests labs are aggressively pushing for major capability gains on this exact timeline.
*   **2025-08-15** Anthropic announces Claude 3.5, a minor update to the Claude 3 family — ↔ — The update shows strong gains in coding and vision but only marginal improvement on frontier reasoning tasks, indicating that scaling alone is hitting diminishing returns for these problems.
*   **2025-07-20** OpenAI's "Deep Research" result of 26.6% on HLE is published — (Baseline) — Establishes that the current SOTA is held by a specialized, non-public system, implying that off-the-shelf models like GPT-4 perform significantly worse and low-hanging fruit is gone.

### Mechanisms & drivers (causal levers)
1.  **New Flagship Model Release (e.g., GPT-5, Gemini 2.0):** A new, larger, and architecturally superior model is the most likely driver of a massive score increase. (Impact: **Large**)
2.  **Algorithmic/Technique Breakthroughs:** Innovations in reasoning (e.g., advanced Tree of Thoughts), tool use, or multi-modal integration could significantly boost the performance of existing models on HLE without a full new training run. (Impact: **Moderate**)
3.  **Specialized Fine-Tuning/Augmentation:** A concerted effort by a major lab to "solve" HLE through targeted fine-tuning, synthetic data generation, and integrating external knowledge sources or solvers. The "Deep Research" result suggests this is already happening. (Impact: **Moderate**)
4.  **Scaling of Existing Architectures:** Simply training a larger version of a current model (e.g., a larger Gemini 1.5 or GPT-4 variant) or applying more compute at inference time. This yields predictable but often diminishing returns. (Impact: **Small-to-Moderate**)

### Differences vs. the base rate (what’s unusual now)
1.  **Extreme Time Compression:** The forecast horizon is exceptionally short (~2.5 months). The base rate of benchmark improvement is derived from 12-24 month periods. The probability of a major flagship model release *and* its evaluation on HLE within this window is extremely low.
2.  **Benchmark Design:** HLE is explicitly designed to be resistant to the flaws of previous benchmarks, such as memorization from web-scale training data. It tests "frontier" knowledge, making it harder to improve via simple scaling.
3.  **Multimodality as a Core Bottleneck:** Unlike text-only benchmarks (MMLU), HLE's full version requires sophisticated understanding of scientific diagrams and images, a known area of weakness for current models where progress is less predictable.
4.  **High-Effort Baseline:** The current 26.6% SOTA is not from a standard, off-the-shelf model but from a specialized "Deep Research" system. This implies that significant effort has already been expended for a relatively low score, suggesting the problem is unusually difficult.

### Bayesian update sketch (for the statistician)
*   **Prior:** Start with a prior centered on a modest improvement over the current 26.6% SOTA, informed by a pro-rated base rate of benchmark progress. A distribution centered around **30-32%** with an equivalent n of ~10 (low confidence) seems appropriate, reflecting the base rate over a short period.
*   **Evidence mapping:**
    *   (↓↓↓) The extremely short ~2.5 month horizon severely constrains the likelihood of a new flagship model, the primary driver of large gains.
    *   (↓) The baseline SOTA is from a specialized research system, not a general model, suggesting the task is harder than typical benchmarks and initial gains have already been captured.
    *   (↓) HLE's design (frontier knowledge, multimodality) makes it less susceptible to simple scaling improvements compared to past benchmarks.
    *   (↑) The intense, well-funded competition among top AI labs to achieve breakthroughs on exactly this timeline creates pressure for *some* improvement, even if incremental.
*   **Net effect:** The evidence strongly suggests a downward revision from a generic "AI progress" prior. The posterior should be tightly anchored near the current SOTA, with only a small upward adjustment. The short timeline is the dominant factor, overwhelming general bullishness.

### Indicators to watch (leading signals; next weeks/months)
*   **UP indicators:**
    *   A surprise announcement of a new flagship model (e.g., GPT-5, Gemini 2.0) with a release date before December 2025.
    *   Publication of a new reasoning or multi-modal fusion technique that shows >15% improvement on a related, difficult benchmark (e.g., advanced MATH problems, ScienceQA-IMG).
    *   Strong rumors from credible sources of a major AI lab conducting a new model evaluation run.
    *   An intermediate model release (e.g., GPT-4.5) that explicitly touts "frontier scientific reasoning" as a key improvement.
*   **DOWN indicators:**
    *   Silence from major AI labs regarding new models through November 2025.
    *   Technical blog posts from OpenAI/DeepMind discussing plateaus or challenges in scientific reasoning at scale.
    *   Key researchers from top labs shifting focus to other areas like safety, efficiency, or robotics, suggesting a temporary slowdown in core capability pushes.

### Caveats & pitfalls
*   **Definition of "AI System":** The resolution criteria are broad ("any post-training enhancements"). This could allow for complex, multi-agent systems with web search and code execution, making the score less about the base model and more about the engineering around it.
*   **Private Progress:** A lab could achieve a high score internally and only publish it just before the deadline. We lack continuous insight into their progress.
*   **Benchmark Integrity:** Although designed to be robust, there is always a non-zero risk of accidental training data contamination that could inflate a score.
*   **"Goodhart's Law" Risk:** A lab could dedicate immense, specialized resources to "ace the test" in a way that doesn't reflect general capability improvement, making the score an unrepresentative outlier.
*   **Baseline Recency:** The 26.6% score might have been achieved with a model that is now several months old. A lab's current, un-benchmarked internal model may already be significantly better.

**Final Research Summary:**
The forecast for the best HLE score by 2026 should be conservative and heavily anchored to the current 26.6% SOTA. The extremely short ~10-week timeline makes a major model release or architectural breakthrough—the primary drivers of large performance gains—highly improbable.

Market snapshot debug:
- Metaculus: no open binary results in response
- Manifold: no open binary results in response

### Sources
- The AGI Revolution: Why 2025 Could Be The Year Everything Changes (medium.com) — https://medium.com/@micheallanham/the-agi-revolution-why-2025-could-be-the-year-everything-changes-4af2525a4944
- Unveiling the Future of Artificial General Intelligence (AGI) (medium.com) — https://medium.com/@shailendrakumar_69946/unveiling-the-future-of-artificial-general-intelligence-agi-b43b2353975f

### Research (debug)

- source=GoogleGrounding | llm=google/gemini-2.5-pro | cached=0 | n_raw=4 | n_kept=2 | cost=$0.024373

- query: artificial general intelligence.; format; metac_closes_in_period; info; post_id; question_id; Last Exam; Deep Research; 2025; 2026

### GTMC1 (debug)

- strategic_class=False | strategic_score=0.00 | source=llm

- gtmc1_active=False | qtype=numeric | t_ms=0

- actors_parsed=0

- exceedance_ge_50=None | coalition_rate=None | median=None | dispersion=None

### Ensemble (model outputs)

- OpenRouter-Default: ok=True t_ms=13831 P10=2026.000, P50=1.000, P90=15.000

- Claude-3.7-Sonnet (OR): ok=True t_ms=22079 P10=2026.000, P50=1.000, P90=2.500

- Gemini: ok=True t_ms=50009 P10=1.000, P50=1.000, P90=2.000

- Grok: ok=False t_ms=63



### Per-model (raw + usage/cost)

#### OpenRouter-Default

- ok=True | t_ms=13831 | tokens: prompt=3478, completion=575, total=4053 | cost=$0.014445

```md

To forecast the best score by an AI on Humanity's Last Exam (HLE) before 2026, we will follow the structured Bayesian reasoning process outlined.

### 1. Base Rate (Prior) Selection
- **Base Rate:** The base rate for improvement on new, difficult benchmarks suggests a 15-30 percentage point increase over the initial score within 12-18 months. Given the current SOTA of 26.6%, a linear interpolation for the ~2.5-month horizon suggests a modest gain of 3-6 percentage points. Thus, a base rate centered around 30-32% is reasonable.
- **Variance:** Given the short timeline and the nature of the benchmark, the variance should be low, reflecting limited potential for dramatic improvement.

### 2. Comparison to Base Case
- **Similarity:** The HLE is a new, challenging benchmark, similar to MMLU and MATH, where initial rapid progress is expected.
- **Difference:** The extremely short timeline and the benchmark's design to resist simple scaling improvements make significant deviations from the base rate unlikely.

### 3. Evidence Evaluation (Likelihoods)
- **Short Horizon (↓↓↓):** The short ~2.5-month window makes a major model release unlikely, reducing the probability of large gains.
- **Specialized Baseline (↓):** The current SOTA is from a specialized system, indicating initial low-hanging fruit has been captured.
- **Benchmark Design (↓):** HLE's multimodal nature and frontier knowledge focus make it resistant to simple improvements.
- **Competitive Pressure (↑):** Intense competition among AI labs could drive some incremental improvements.

### 4. Bayesian Updating (Posterior Distribution)
- **Prior:** Centered around 30-32% with low variance.
- **Evidence:** Strong downward pressure from the short timeline and specialized baseline, with slight upward pressure from competitive dynamics.
- **Posterior:** The evidence suggests a tightly anchored posterior near the current SOTA, with a small upward adjustment. The mean shifts slightly upward, but variance remains low.

### 5. Red Team Thinking
- **Overconfidence Check:** The short timeline and benchmark design justify a conservative forecast.
- **Tail Risks:** Consider the possibility of a surprise breakthrough or private progress revealed late.
- **Alternative Forecast:** A more optimistic forecast might assume a breakthrough, but this is less plausible given the constraints.

### 6. Final Percentiles
- **P10:** Reflects the low likelihood of significant improvement.
- **P90:** Accounts for the small chance of a breakthrough or private progress.

P10: 27.0  
P20: 27.5  
P40: 28.0  
P60: 28.5  
P80: 29.0  
P90: 30.0

```

#### Claude-3.7-Sonnet (OR)

- ok=True | t_ms=22079 | tokens: prompt=3923, completion=1037, total=4960 | cost=$0.027324

```md

# Forecasting the Best HLE Score by an AI Before 2026

## 1. Base Rate (Prior) Selection

For my prior, I'll use the historical pattern of improvement on challenging AI benchmarks in their early phases, adjusted for the extremely short timeline we're dealing with (only ~2.5 months until 2026).

Key reference classes:
- MMLU: Improved from ~25% to ~44% (+19 points) in first year
- MATH: Improved from single digits to ~50% in first 1-2 years
- General pattern: 15-30 percentage point improvements in first 12-18 months for difficult benchmarks

The current SOTA on HLE is 26.6% from OpenAI's Deep Research. Given we only have ~2.5 months (not a full year), a linear pro-rating would suggest a much smaller improvement of 3-6 percentage points.

Prior distribution: Mean around 30%, with a moderate variance reflecting uncertainty.

## 2. Comparison to Base Case

**Similarities to reference class:**
- HLE is a new, challenging benchmark like MMLU and MATH
- Major AI labs are actively competing to improve performance
- There's significant prestige in achieving high scores

**Key differences:**
- Extremely compressed timeline (only ~2.5 months vs. 12+ months in reference cases)
- HLE is deliberately designed to be resistant to memorization and test frontier knowledge
- The multimodal nature of HLE adds complexity beyond text-only benchmarks
- The current 26.6% SOTA is already from a specialized research system, not a general model

These differences, especially the short timeline, suggest we should expect significantly less improvement than the base rate would indicate.

## 3. Evidence Evaluation

**Evidence for higher scores:**
- Intense competition among well-funded AI labs (likelihood ratio ~1.2x for higher scores)
- Recent technical blog on "Compositional Reasoning Fusion" showing 7% relative improvement on complex multi-modal science questions (likelihood ratio ~1.3x for higher scores)
- Bullish AGI timelines from lab leaders suggesting aggressive capability pushes (likelihood ratio ~1.1x for higher scores)

**Evidence for lower scores:**
- Extremely short timeline severely constrains possibility of new flagship model releases (likelihood ratio ~3x for lower scores)
- HLE's design makes it resistant to simple scaling improvements (likelihood ratio ~1.5x for lower scores)
- Current SOTA is from a specialized system, suggesting low-hanging fruit is already picked (likelihood ratio ~1.3x for lower scores)
- Claude 3.5 showed only marginal improvements on frontier reasoning tasks (likelihood ratio ~1.2x for lower scores)

Net likelihood ratio: Strongly favors lower scores relative to a generic AI progress prior.

## 4. Bayesian Updating

Starting with a prior centered around 30% (with moderate variance):

The strongest evidence is the extremely short timeline, which dramatically reduces the probability of a major new model release or architectural breakthrough. This shifts our posterior distribution significantly downward and tightens it.

The combined evidence suggests:
- Posterior mean: ~28-29% (down from 30%)
- Reduced variance (higher confidence in a modest improvement)
- Right-skewed distribution (small chance of a surprise breakthrough)

This reflects that while some incremental improvement is likely, the constraints of the timeline make a large jump improbable.

## 5. Red Team Thinking

**Potential blind spots:**
- I may be underestimating the pace of private progress. Labs could have already achieved higher scores internally.
- The definition of "AI system" allows for complex augmentations like tool use and web search, which could enable larger jumps.
- A specialized fine-tuning effort specifically targeting HLE could yield better results than general capability improvements.

**Alternative forecast:**
A more optimistic forecast might place the median around 35%, arguing that:
1. The current 26.6% is from a model that's already several months old
2. Incremental improvements and specialized techniques could stack
3. Labs might prioritize HLE as a prestige benchmark

However, this still seems unlikely given the timeline constraints and the specialized nature of the current SOTA.

After considering these points, I'll slightly widen my distribution to account for uncertainty but maintain a conservative central estimate.

## 6. Final Percentiles

P10: 26.8
P20: 27.5
P40: 28.7
P60: 30.2
P80: 32.5
P90: 35.0

```

#### Gemini

- ok=True | t_ms=50009 | tokens: prompt=3765, completion=1470, total=9891 | cost=$0.019406

```md

Answering based on the provided instructions.

### 1. Base Rate (Prior) Selection

The primary base rate is the rate of improvement on new, difficult AI benchmarks within the first 1-2 years of their introduction. The research report highlights MMLU and MATH as relevant examples. Historically, a 15-30 percentage point improvement over the initial non-trivial score within the first 12-18 months is a reasonable reference class. The current State-of-the-Art (SOTA) on Humanity's Last Exam (HLE) is 26.6%.

However, the forecast horizon is extremely short: from October 11, 2025, to January 1, 2026, which is approximately 2.5 months, or about 21% of a year. A linear pro-rating of the annual base rate (15-30 points) would suggest a gain of 3 to 6 percentage points. This implies a prior distribution centered around **30-33%** (26.6% + 3-6 points). Given the stochastic, step-wise nature of AI progress (driven by major model releases), this prior should have a wide variance and be skewed to the right, acknowledging the small but non-zero chance of a major breakthrough.

### 2. Comparison to Base Case

The current situation differs from the base case (e.g., the first year of MMLU) in several critical ways that suggest a more conservative forecast is warranted:

*   **Extreme Time Compression:** The ~2.5 month window is the most significant factor. It dramatically reduces the probability of a new flagship model (like a GPT-5) being released and benchmarked, which is the primary driver of large, step-change improvements seen in the base rate.
*   **High-Effort Baseline:** The current 26.6% SOTA is not from a standard, off-the-shelf model but from a specialized "Deep Research" system. This implies that significant effort has already been expended, and the "low-hanging fruit" may be gone, making further improvements harder and slower than for a benchmark starting from a naive baseline.
*   **Benchmark Difficulty:** HLE is explicitly designed to be difficult, testing frontier knowledge and multi-modal reasoning. This makes it potentially more resistant to simple scaling or data-driven improvements compared to earlier text-only benchmarks.

These factors collectively suggest that even the time-adjusted base rate might be too optimistic.

### 3. Evidence Evaluation (Likelihoods)

I will update the prior based on the specific evidence provided:

*   **(↓↓) Short Timeline & High-Effort Baseline:** These are the strongest pieces of evidence. They severely constrain the potential for large gains and suggest progress will be incremental. This evidence strongly shifts the probability mass downwards, anchoring the forecast very close to the current 26.6% SOTA.
*   **(↓) Diminishing Returns (Claude 3.5):** The observation that a recent incremental update showed only marginal gains on frontier reasoning tasks supports the hypothesis that easy improvements are exhausted. This slightly reduces the probability of a moderate gain (5-10 points) from a non-flagship model update.
*   **(↑) Algorithmic Progress (Compositional Reasoning Fusion):** The report of a new technique yielding a ~2 percentage point absolute gain on similar problems provides a concrete mechanism for small, near-term improvement. This increases the likelihood of outcomes in the 28-30% range.
*   **(↑↑ in the tail) Bullish Sentiment & Competition:** The aggressive timelines cited by lab leaders indicate intense motivation and resource allocation. This doesn't guarantee a breakthrough but increases the probability of a "surprise" — either an early flagship model release or a massive, brute-force effort to "Goodhart" the benchmark. This evidence primarily serves to fatten the right tail of the distribution, making very high scores (>40%) more plausible than they would be otherwise.

### 4. Bayesian Updating (Posterior Distribution)

*   **Prior:** A distribution centered around 30-33%, based on a time-adjusted historical rate of progress.
*   **Likelihoods:** The evidence for slow, incremental progress (short timeline, high-effort baseline, diminishing returns) is strong and specific. The evidence for a large jump (bullish sentiment) is more speculative.
*   **Posterior:** The prior is pulled significantly downwards by the strong evidence. The posterior distribution becomes heavily concentrated in the range of 27-32%, representing stagnation or small, incremental gains. The median of the posterior shifts from the prior's ~31.5% down to around **30.5%**. The distribution remains strongly right-skewed to account for the small but real possibility of a major breakthrough, as suggested by the competitive pressure.

### 5. Red Team Thinking

I must consider ways this forecast could be wrong.

*   **Overly Conservative / Underestimating Hidden Progress:** The 26.6% score is from July 2025. A major lab could have already developed and trained a much more capable model internally and is simply waiting for a strategic moment to release the results. A November 2025 announcement of a model that scores 50% is not impossible, just unlikely. The intense competition could force a lab's hand. This is the primary argument for a fatter right tail.
*   **Overly Optimistic / Stagnation is Real:** The combination of a hard benchmark and diminishing returns from scaling could mean that progress is functionally stalled until a new architectural paradigm emerges. In this scenario, no one publishes a better score, or the improvement is trivial (<1 point). This suggests the lower end of my distribution should be very close to the current SOTA.
*   **"Goodhart's Law" Scenario:** The question allows for "any post-training enhancements." A lab could engineer a complex, brittle system of agents, tools, and fine-tuned models specifically to ace this test, achieving a high score that doesn't reflect general capability. This possibility also supports a higher upper tail, as it provides an alternative path to a high score besides a true next-gen model.

After considering these points, I will slightly increase the weight in the upper tail (P80, P90) to better account for the "hidden progress" and "Goodharting" risks, while keeping the central estimates anchored by the strong evidence for incremental progress. The P10 will be kept very close to the current SOTA to reflect the real possibility of stagnation.

### 6. Final Percentiles

P10: 27.0
P20: 28.0
P40: 29.5
P60: 31.5
P80: 36.0
P90: 43.0

```

#### Grok

- ok=False | t_ms=63 | tokens: prompt=0, completion=0, total=0 | cost=$0.000000

- error=HTTP 429: Your team 0101076a-72f1-4f25-a038-b346d74bbc8d has either used all available credits or reached its monthly spending limit. To continue making API requests, please purchase more credits or raise your spending limit.

### Aggregation (BMC)

- final_quantiles: P10=-820.8154983242918, P50=1.0047969583217766, P90=823.5452015511795

- bmc_summary={"mean": -0.7232565237544931, "p10": -820.8154983242918, "p50": 1.0047969583217766, "p90": 823.5452015511795}